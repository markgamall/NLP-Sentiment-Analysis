{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":11574224,"sourceType":"datasetVersion","datasetId":7256627}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install pyspellchecker","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:14:14.548143Z","iopub.execute_input":"2025-04-27T00:14:14.548537Z","iopub.status.idle":"2025-04-27T00:14:18.607127Z","shell.execute_reply.started":"2025-04-27T00:14:14.548513Z","shell.execute_reply":"2025-04-27T00:14:18.606271Z"}},"outputs":[{"name":"stdout","text":"Collecting pyspellchecker\n  Downloading pyspellchecker-0.8.2-py3-none-any.whl.metadata (9.4 kB)\nDownloading pyspellchecker-0.8.2-py3-none-any.whl (7.1 MB)\n\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m70.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hInstalling collected packages: pyspellchecker\nSuccessfully installed pyspellchecker-0.8.2\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"!pip install tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:14:18.609048Z","iopub.execute_input":"2025-04-27T00:14:18.609642Z","iopub.status.idle":"2025-04-27T00:14:21.511579Z","shell.execute_reply.started":"2025-04-27T00:14:18.609612Z","shell.execute_reply":"2025-04-27T00:14:21.510863Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Loading & Preprocessing scale_data Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nbase_path = '/kaggle/input/nlp-sentiment-analysis-project/scale_data/scaledata'\n\ncritics = ['Dennis+Schwartz', 'James+Berardinelli', 'Scott+Renshaw', 'Steve+Rhodes']\n\nall_dfs = []\n\nfor critic in critics:\n    critic_path = os.path.join(base_path, critic)\n    \n    id_df = pd.read_csv(os.path.join(critic_path, f'id.{critic}'), header=None, names=['id'])\n    label_3class_df = pd.read_csv(os.path.join(critic_path, f'label.3class.{critic}'), header=None, names=['label_3class'])\n    label_4class_df = pd.read_csv(os.path.join(critic_path, f'label.4class.{critic}'), header=None, names=['label_4class'])\n    rating_df = pd.read_csv(os.path.join(critic_path, f'rating.{critic}'), header=None, names=['rating'])\n    \n    with open(os.path.join(critic_path, f'subj.{critic}'), 'r', encoding='utf-8') as f:\n        subj_lines = f.read().splitlines()\n    subj_df = pd.DataFrame(subj_lines, columns=['subjectivity'])\n    \n    critic_df = pd.concat([id_df, label_3class_df, label_4class_df, rating_df, subj_df], axis=1)\n    critic_df['critic_name'] = critic\n\n    all_dfs.append(critic_df)\n\n\nfull_df = pd.concat(all_dfs, ignore_index=True)\n\nprint(\"Shape of full dataset:\", full_df.shape)\nprint(\"\\n Columns:\", full_df.columns.tolist())\n\n\nprint(\"\\n First 5 rows:\\n\", full_df.head())\n\n\nprint(\"\\n Value counts for 3-class labels:\\n\", full_df['label_3class'].value_counts())\nprint(\"\\n Unique 3-class labels:\", full_df['label_3class'].unique())\n\nprint(\"\\n Value counts for 4-class labels:\\n\", full_df['label_4class'].value_counts())\nprint(\"\\n Unique 4-class labels:\", full_df['label_4class'].unique())\n\n\nprint(\"\\n Missing values per column:\\n\", full_df.isnull().sum())\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:13:59.058097Z","iopub.execute_input":"2025-04-27T00:13:59.058764Z","iopub.status.idle":"2025-04-27T00:13:59.665380Z","shell.execute_reply.started":"2025-04-27T00:13:59.058739Z","shell.execute_reply":"2025-04-27T00:13:59.664448Z"}},"outputs":[{"name":"stdout","text":"üìå Shape of full dataset: (5006, 6)\n\nüìå Columns: ['id', 'label_3class', 'label_4class', 'rating', 'subjectivity', 'critic_name']\n\nüìå First 5 rows:\n       id  label_3class  label_4class  rating  \\\n0  29420             0             0     0.1   \n1  17219             0             0     0.2   \n2  18406             0             0     0.2   \n3  18648             0             0     0.2   \n4  20021             0             0     0.2   \n\n                                        subjectivity      critic_name  \n0  in my opinion , a movie reviewer's most import...  Dennis+Schwartz  \n1  you can watch this movie , that is based on a ...  Dennis+Schwartz  \n2  this is asking a lot to believe , and though i...  Dennis+Schwartz  \n3  no heroes and no story are the main attributes...  Dennis+Schwartz  \n4  this is not an art movie , yet i saw it an art...  Dennis+Schwartz  \n\nüìå Value counts for 3-class labels:\n label_3class\n1    1915\n2    1894\n0    1197\nName: count, dtype: int64\n\nüìå Unique 3-class labels: [0 1 2]\n\nüìå Value counts for 4-class labels:\n label_4class\n2    1998\n1    1553\n3     840\n0     615\nName: count, dtype: int64\n\nüìå Unique 4-class labels: [0 1 2 3]\n\nüìå Missing values per column:\n id              0\nlabel_3class    0\nlabel_4class    0\nrating          0\nsubjectivity    0\ncritic_name     0\ndtype: int64\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"df = full_df[['subjectivity', 'label_3class']].copy()\n\ndf = df.rename(columns={\n    'subjectivity': 'text',\n    'label_3class': 'label'\n})\n\ndf['label'] = df['label'].map(lambda x: 0 if x == 0 else 1)\n\nprint(f\"‚úÖ Final shape: {df.shape}\")\nprint(f\"\\n‚úÖ First 5 rows:\\n{df.head()}\")\nprint(f\"\\n‚úÖ Label distribution:\\n{df['label'].value_counts()}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:13:59.666819Z","iopub.execute_input":"2025-04-27T00:13:59.667637Z","iopub.status.idle":"2025-04-27T00:13:59.685721Z","shell.execute_reply.started":"2025-04-27T00:13:59.667607Z","shell.execute_reply":"2025-04-27T00:13:59.684976Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Final shape: (5006, 2)\n\n‚úÖ First 5 rows:\n                                                text  label\n0  in my opinion , a movie reviewer's most import...      0\n1  you can watch this movie , that is based on a ...      0\n2  this is asking a lot to believe , and though i...      0\n3  no heroes and no story are the main attributes...      0\n4  this is not an art movie , yet i saw it an art...      0\n\n‚úÖ Label distribution:\nlabel\n1    3809\n0    1197\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"# Loading & Preprocessing rt-polaritydata Dataset","metadata":{}},{"cell_type":"code","source":"neg_file = '/kaggle/input/nlp-sentiment-analysis-project/rt-polaritydata/rt-polaritydata/rt-polarity.neg'\npos_file = '/kaggle/input/nlp-sentiment-analysis-project/rt-polaritydata/rt-polaritydata/rt-polarity.pos'\n\nwith open(neg_file, 'r', encoding='latin-1') as f:\n    neg_lines = f.readlines()\n\nwith open(pos_file, 'r', encoding='latin-1') as f:\n    pos_lines = f.readlines()\n\ndf_rt_polarity = pd.DataFrame({\n    'text': [line.strip() for line in neg_lines + pos_lines],\n    'label': [0]*len(neg_lines) + [1]*len(pos_lines)\n})\n\nprint(df_rt_polarity.head())\nprint(df_rt_polarity['label'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:13:59.686497Z","iopub.execute_input":"2025-04-27T00:13:59.686761Z","iopub.status.idle":"2025-04-27T00:13:59.886066Z","shell.execute_reply.started":"2025-04-27T00:13:59.686737Z","shell.execute_reply":"2025-04-27T00:13:59.885345Z"}},"outputs":[{"name":"stdout","text":"                                                text  label\n0                   simplistic , silly and tedious .      0\n1  it's so laddish and juvenile , only teenage bo...      0\n2  exploitative and largely devoid of the depth o...      0\n3  [garbus] discards the potential for pathologic...      0\n4  a visually flashy but narratively opaque and e...      0\nlabel\n0    5331\n1    5331\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# Loading & Preprocessing review_polarity Dataset","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\n\nbase_path = '/kaggle/input/nlp-sentiment-analysis-project/review_polarity/txt_sentoken'\nneg_path = os.path.join(base_path, 'neg')\npos_path = os.path.join(base_path, 'pos')\n\nneg_reviews = []\nfor file in os.listdir(neg_path):\n    with open(os.path.join(neg_path, file), 'r', encoding='utf-8') as f:\n        neg_reviews.append(f.read())\n\npos_reviews = []\nfor file in os.listdir(pos_path):\n    with open(os.path.join(pos_path, file), 'r', encoding='utf-8') as f:\n        pos_reviews.append(f.read())\n\ndf_txt_sentoken = pd.DataFrame({\n    'text': neg_reviews + pos_reviews,\n    'label': [0]*len(neg_reviews) + [1]*len(pos_reviews)\n})\n\nprint(df_txt_sentoken.head())\nprint(df_txt_sentoken['label'].value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:13:59.954831Z","iopub.execute_input":"2025-04-27T00:13:59.955427Z","iopub.status.idle":"2025-04-27T00:14:12.777078Z","shell.execute_reply.started":"2025-04-27T00:13:59.955405Z","shell.execute_reply":"2025-04-27T00:14:12.776349Z"}},"outputs":[{"name":"stdout","text":"                                                text  label\n0  words i thought i'd never write : the sequel t...      0\n1   \" tina ! ! ! fetch me the axe ! ! ! \" \\na fav...      0\n2  hav plenty , as we are told in the beginning a...      0\n3  the first scene of operation condor has jackie...      0\n4  the title is taken from the writings of ralph ...      0\nlabel\n0    1000\n1    1000\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"# Text Preprocessing for Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"import nltk\nfrom nltk.corpus import stopwords, wordnet\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import pos_tag, word_tokenize\nimport string\nimport re\nfrom spellchecker import SpellChecker\nimport emoji\n\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('averaged_perceptron_tagger_eng')\nnltk.download('stopwords')\n\nstop_words = set(stopwords.words('english'))\nlemmatizer = WordNetLemmatizer()\nspell = SpellChecker()\n\nslang_dict = {\n    \"gr8\": \"great\",\n    \"luv\": \"love\",\n    \"bff\": \"best friend\",\n    \"omg\": \"oh my god\",\n    \"ttyl\": \"talk to you later\",\n    \"brb\": \"be right back\",\n    \"idk\": \"i don't know\",\n    \"smh\": \"shaking my head\"\n}\n\ndef get_wordnet_pos(word):\n    tag = pos_tag([word])[0][1][0].upper()\n    tag_dict = {\n        'J': wordnet.ADJ, \n        'N': wordnet.NOUN, \n        'V': wordnet.VERB, \n        'R': wordnet.ADV\n    }\n    return tag_dict.get(tag, wordnet.NOUN)  # Default to noun if unknown\n\ndef handle_negations(text):\n    negations = [\"not\", \"no\", \"never\", \"none\", \"n't\"]\n    words = text.split()\n    for i, word in enumerate(words):\n        if word in negations and i + 1 < len(words):\n            words[i + 1] = f\"not_{words[i + 1]}\"  # Prefix with 'not_'\n    return \" \".join(words)\n\ndef handle_emojis(text):\n    return emoji.demojize(text)\n\ndef correct_spelling(text):\n    words = text.split()\n    corrected_words = []\n    for word in words:\n        # If the word is not in the stopwords list, correct the spelling\n        if word not in stop_words:\n            corrected_word = spell.correction(word)\n            if corrected_word is not None:\n                corrected_words.append(corrected_word)\n            else:\n                corrected_words.append(word)  # If no correction found, keep the word as is\n        else:\n            corrected_words.append(word)\n    return \" \".join(corrected_words)\n\ndef handle_slang(text):\n    words = text.split()\n    return \" \".join([slang_dict.get(word, word) for word in words])\n\ndef preprocess_text(text):\n    # 1. Lowercase\n    text = text.lower()\n    \n    # 2. Remove HTML Tags\n    text = re.sub(r'<.*?>', '', text)\n    \n    # 3. Remove punctuation\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    \n    # 4. Remove numbers\n    text = re.sub(r'\\d+', '', text)\n    \n    # 5. Handle Emojis\n    text = handle_emojis(text)\n    \n    # 6. Handle Negations\n    text = handle_negations(text)\n    \n    # 7. Correct spelling\n    #text = correct_spelling(text)\n    \n    # 8. Remove extra spaces\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    # 9. Remove Hashtags and Mentions (for social media data)\n    text = re.sub(r'@\\w+|#\\w+', '', text)  # Removes mentions and hashtags\n    \n    # 10. Handle Slang\n    text = handle_slang(text)\n    \n    # 11. Tokenize\n    tokens = word_tokenize(text)\n    \n    # 12. Remove stopwords\n    tokens = [word for word in tokens if word not in stop_words]\n    \n    # 13. Lemmatization with correct POS tag\n    tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in tokens]\n    \n    return ' '.join(tokens)\n\nfrom tqdm import tqdm\n\ntqdm.pandas()\n\ncombined_df['clean_text'] = combined_df['text'].progress_apply(preprocess_text)\nfinal_df = combined_df[['clean_text', 'label']]\n\nprint(final_df.head())\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:15:45.781494Z","iopub.execute_input":"2025-04-27T00:15:45.781766Z","iopub.status.idle":"2025-04-27T00:17:49.072935Z","shell.execute_reply.started":"2025-04-27T00:15:45.781746Z","shell.execute_reply":"2025-04-27T00:17:49.072191Z"}},"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n[nltk_data]       date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 17668/17668 [02:03<00:00, 143.48it/s]","output_type":"stream"},{"name":"stdout","text":"                                          clean_text  label\n0                  film really not_so much bad bland      0\n1  sometimes incisive sensitive portrait undercut...      0\n2  kind nervous film either give mild headache ex...      1\n3  falsehood pile undermine movie reality stifle ...      0\n4  hoffman notch nuance pain smart edgy voice wad...      1\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":11},{"cell_type":"markdown","source":"# Saving the final dataset","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n\n\nsave_folder = \"cleaned_dataset__\"\nos.makedirs(save_folder, exist_ok=True)\n\nfinal_df.to_csv(os.path.join(save_folder, \"data.csv\"), index=False)\n\nprint(f\"Dataset saved locally inside '{save_folder}/data.csv'. You can upload it manually to Kaggle later.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:22:18.257421Z","iopub.execute_input":"2025-04-27T00:22:18.257933Z","iopub.status.idle":"2025-04-27T00:22:18.617774Z","shell.execute_reply.started":"2025-04-27T00:22:18.257880Z","shell.execute_reply":"2025-04-27T00:22:18.617188Z"}},"outputs":[{"name":"stdout","text":"Dataset saved locally inside 'cleaned_dataset__/data.csv'. You can upload it manually to Kaggle later.\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\nimport os\n\n\nfull_df_binary = full_df[['subjectivity', 'label_3class']].copy()\nfull_df_binary.rename(columns={'subjectivity': 'text'}, inplace=True)\n\nfull_df_binary['label'] = full_df_binary['label_3class'].map(lambda x: 0 if x == 0 else 1)\n\n\nfull_df_binary.drop(columns=['label_3class'], inplace=True)\n\nprint(f\"Processed full_df shape: {full_df_binary.shape}\")\n\n\n\ntxt_sentoken_base = '/kaggle/input/nlp-sentiment-analysis-project/review_polarity/txt_sentoken'\nneg_path = os.path.join(txt_sentoken_base, 'neg')\npos_path = os.path.join(txt_sentoken_base, 'pos')\n\nneg_reviews = []\nfor file in os.listdir(neg_path):\n    with open(os.path.join(neg_path, file), 'r', encoding='utf-8') as f:\n        neg_reviews.append(f.read())\n\npos_reviews = []\nfor file in os.listdir(pos_path):\n    with open(os.path.join(pos_path, file), 'r', encoding='utf-8') as f:\n        pos_reviews.append(f.read())\n\ndf_txt_sentoken = pd.DataFrame({\n    'text': neg_reviews + pos_reviews,\n    'label': [0]*len(neg_reviews) + [1]*len(pos_reviews)\n})\n\nprint(f\"Processed txt_sentoken shape: {df_txt_sentoken.shape}\")\n\n\nneg_file = '/kaggle/input/nlp-sentiment-analysis-project/rt-polaritydata/rt-polaritydata/rt-polarity.neg'\npos_file = '/kaggle/input/nlp-sentiment-analysis-project/rt-polaritydata/rt-polaritydata/rt-polarity.pos'\n\nwith open(neg_file, 'r', encoding='latin-1') as f:\n    neg_lines = f.readlines()\n\nwith open(pos_file, 'r', encoding='latin-1') as f:\n    pos_lines = f.readlines()\n\ndf_rt_polarity = pd.DataFrame({\n    'text': [line.strip() for line in neg_lines + pos_lines],\n    'label': [0]*len(neg_lines) + [1]*len(pos_lines)\n})\n\nprint(f\"Processed rt_polaritydata shape: {df_rt_polarity.shape}\")\n\n\ncombined_df = pd.concat([full_df_binary, df_txt_sentoken, df_rt_polarity], axis=0, ignore_index=True)\n\nprint(f\"‚úÖ Final combined dataset shape: {combined_df.shape}\")\n\ncombined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)\n\ncombined_df.to_csv('final_sentiment_dataset.csv', index=False)\n\nprint(\"üéØ Dataset ready with two columns: text and label!\")\nprint(combined_df.head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:14:12.778357Z","iopub.execute_input":"2025-04-27T00:14:12.778634Z","iopub.status.idle":"2025-04-27T00:14:14.547330Z","shell.execute_reply.started":"2025-04-27T00:14:12.778609Z","shell.execute_reply":"2025-04-27T00:14:14.546311Z"}},"outputs":[{"name":"stdout","text":"Processed full_df shape: (5006, 2)\nProcessed txt_sentoken shape: (2000, 2)\nProcessed rt_polaritydata shape: (10662, 2)\n‚úÖ Final combined dataset shape: (17668, 2)\nüéØ Dataset ready with two columns: text and label!\n                                                text  label\n0      the film is really not so much bad as bland .      0\n1  a sometimes incisive and sensitive portrait th...      0\n2  the kind of nervous film that will either give...      1\n3  falsehoods pile up , undermining the movie's r...      0\n4  hoffman notches in the nuances of pain , but h...      1\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# Assuming your DataFrame is called `df`\nvalue_counts = final_df['label'].value_counts()\n\nprint(value_counts)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T00:22:03.361427Z","iopub.execute_input":"2025-04-27T00:22:03.362162Z","iopub.status.idle":"2025-04-27T00:22:03.367051Z","shell.execute_reply.started":"2025-04-27T00:22:03.362137Z","shell.execute_reply":"2025-04-27T00:22:03.366332Z"}},"outputs":[{"name":"stdout","text":"label\n1    10140\n0     7528\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":16}]}